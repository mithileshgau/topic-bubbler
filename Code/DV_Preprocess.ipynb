{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the input data to extract Topic and Sub-Topic using Dual-LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in d:\\asu\\dv\\project\\data\\.venv\\lib\\site-packages (15.0.2)\n",
      "Requirement already satisfied: numpy<2,>=1.16.6 in d:\\asu\\dv\\project\\data\\.venv\\lib\\site-packages (from pyarrow) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: d:\\ASU\\DV\\Project\\Data\\.venv\\Scripts\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\asu\\dv\\project\\data\\.venv\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in d:\\asu\\dv\\project\\data\\.venv\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\asu\\dv\\project\\data\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\asu\\dv\\project\\data\\.venv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\asu\\dv\\project\\data\\.venv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\asu\\dv\\project\\data\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: d:\\ASU\\DV\\Project\\Data\\.venv\\Scripts\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Obtaining dependency information for nltk from https://files.pythonhosted.org/packages/a6/0a/0d20d2c0f16be91b9fa32a77b76c60f9baf6eba419e5ef5deca17af9c582/nltk-3.8.1-py3-none-any.whl.metadata\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting click (from nltk)\n",
      "  Obtaining dependency information for click from https://files.pythonhosted.org/packages/00/2e/d53fa4befbf2cfa713304affc7ca780ce4fc1fd8710527771b58311a3229/click-8.1.7-py3-none-any.whl.metadata\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting joblib (from nltk)\n",
      "  Obtaining dependency information for joblib from https://files.pythonhosted.org/packages/10/40/d551139c85db202f1f384ba8bcf96aca2f329440a844f924c8a0040b6d02/joblib-1.3.2-py3-none-any.whl.metadata\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Obtaining dependency information for regex>=2021.8.3 from https://files.pythonhosted.org/packages/a8/01/18232f93672c1d530834e2e0568a80eaab1df12d67ae499b1762ab462b5c/regex-2023.12.25-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading regex-2023.12.25-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ------------------ ------------------- 20.5/42.0 kB 320.0 kB/s eta 0:00:01\n",
      "     -------------------------------------- 42.0/42.0 kB 503.7 kB/s eta 0:00:00\n",
      "Collecting tqdm (from nltk)\n",
      "  Obtaining dependency information for tqdm from https://files.pythonhosted.org/packages/2a/14/e75e52d521442e2fcc9f1df3c5e456aead034203d4797867980de558ab34/tqdm-4.66.2-py3-none-any.whl.metadata\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.6 kB ? eta -:--:--\n",
      "     ----------------------------------- ---- 51.2/57.6 kB 1.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 57.6/57.6 kB 1.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in d:\\asu\\dv\\project\\data\\.venv\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.2/1.5 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.7/1.5 MB 9.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.2/1.5 MB 9.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.4/1.5 MB 10.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.5/1.5 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 6.0 MB/s eta 0:00:00\n",
      "Downloading regex-2023.12.25-cp311-cp311-win_amd64.whl (269 kB)\n",
      "   ---------------------------------------- 0.0/269.5 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 30.7/269.5 kB 1.3 MB/s eta 0:00:01\n",
      "   ----------- --------------------------- 81.9/269.5 kB 919.0 kB/s eta 0:00:01\n",
      "   --------------------- ------------------ 143.4/269.5 kB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 204.8/269.5 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 269.5/269.5 kB 1.3 MB/s eta 0:00:00\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "   ---------------------------------------- 0.0/302.2 kB ? eta -:--:--\n",
      "   ------------------ --------------------- 143.4/302.2 kB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 302.2/302.2 kB 3.7 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.3/78.3 kB 2.2 MB/s eta 0:00:00\n",
      "Installing collected packages: tqdm, regex, joblib, click, nltk\n",
      "Successfully installed click-8.1.7 joblib-1.3.2 nltk-3.8.1 regex-2023.12.25 tqdm-4.66.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: d:\\ASU\\DV\\Project\\Data\\.venv\\Scripts\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Obtaining dependency information for gensim from https://files.pythonhosted.org/packages/ad/97/b8253236dfedb9094f4273393a3fd03997da81f27f15822e56128da894ae/gensim-4.3.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached gensim-4.3.2-cp311-cp311-win_amd64.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in d:\\asu\\dv\\project\\data\\.venv\\lib\\site-packages (from gensim) (1.26.4)\n",
      "Collecting scipy>=1.7.0 (from gensim)\n",
      "  Obtaining dependency information for scipy>=1.7.0 from https://files.pythonhosted.org/packages/9a/25/5b30cb3efc9566f0ebeaeca1976150316353c17031ad7868ef46de5ab8dc/scipy-1.12.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading scipy-1.12.0-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.4 kB ? eta -:--:--\n",
      "     ------------ ------------------------- 20.5/60.4 kB 640.0 kB/s eta 0:00:01\n",
      "     -------------------------------- ----- 51.2/60.4 kB 525.1 kB/s eta 0:00:01\n",
      "     -------------------------------------- 60.4/60.4 kB 534.1 kB/s eta 0:00:00\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "  Obtaining dependency information for smart-open>=1.8.1 from https://files.pythonhosted.org/packages/65/12/cc24847b4b0b124501a33cd8f7963f79f6f6584bc7f2f4fc16bbbaa54c8f/smart_open-7.0.4-py3-none-any.whl.metadata\n",
      "  Downloading smart_open-7.0.4-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting wrapt (from smart-open>=1.8.1->gensim)\n",
      "  Obtaining dependency information for wrapt from https://files.pythonhosted.org/packages/cf/c3/0084351951d9579ae83a3d9e38c140371e4c6b038136909235079f2e6e78/wrapt-1.16.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading wrapt-1.16.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Using cached gensim-4.3.2-cp311-cp311-win_amd64.whl (24.0 MB)\n",
      "Downloading scipy-1.12.0-cp311-cp311-win_amd64.whl (46.2 MB)\n",
      "   ---------------------------------------- 0.0/46.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/46.2 MB 3.3 MB/s eta 0:00:14\n",
      "   ---------------------------------------- 0.3/46.2 MB 6.8 MB/s eta 0:00:07\n",
      "   ---------------------------------------- 0.4/46.2 MB 4.2 MB/s eta 0:00:11\n",
      "    --------------------------------------- 0.9/46.2 MB 6.0 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 1.3/46.2 MB 6.8 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 1.8/46.2 MB 7.6 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 2.3/46.2 MB 8.1 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 2.8/46.2 MB 9.0 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 3.3/46.2 MB 9.6 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 3.8/46.2 MB 9.7 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 4.3/46.2 MB 9.7 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 4.8/46.2 MB 9.9 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 5.0/46.2 MB 9.7 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 5.5/46.2 MB 10.3 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 5.5/46.2 MB 10.3 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 5.5/46.2 MB 8.6 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 6.0/46.2 MB 8.9 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 6.4/46.2 MB 8.9 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 6.8/46.2 MB 9.1 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 7.4/46.2 MB 9.2 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 7.9/46.2 MB 9.7 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 8.5/46.2 MB 9.7 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 9.1/46.2 MB 10.1 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 9.6/46.2 MB 10.0 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 10.0/46.2 MB 10.3 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 10.8/46.2 MB 11.3 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 11.4/46.2 MB 11.3 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 11.8/46.2 MB 11.5 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 12.5/46.2 MB 11.3 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 13.1/46.2 MB 11.5 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 13.5/46.2 MB 11.3 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 14.1/46.2 MB 11.5 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 14.6/46.2 MB 11.5 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 14.8/46.2 MB 11.1 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 15.6/46.2 MB 11.5 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 16.2/46.2 MB 12.8 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 16.5/46.2 MB 12.8 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 17.2/46.2 MB 13.1 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 17.7/46.2 MB 12.8 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 18.1/46.2 MB 12.6 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 18.7/46.2 MB 12.6 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 19.3/46.2 MB 12.6 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 19.7/46.2 MB 12.6 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 20.2/46.2 MB 12.1 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 20.7/46.2 MB 12.6 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 21.3/46.2 MB 12.4 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 21.7/46.2 MB 12.4 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 22.3/46.2 MB 12.4 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 22.8/46.2 MB 12.4 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 23.2/46.2 MB 12.1 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 23.6/46.2 MB 12.1 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 24.2/46.2 MB 12.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 24.4/46.2 MB 11.7 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 24.9/46.2 MB 12.4 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 25.5/46.2 MB 12.3 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 26.1/46.2 MB 12.1 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 26.5/46.2 MB 12.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 26.9/46.2 MB 12.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 27.0/46.2 MB 11.7 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 27.6/46.2 MB 11.7 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 28.0/46.2 MB 11.5 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 28.3/46.2 MB 11.5 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 28.5/46.2 MB 11.5 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 28.7/46.2 MB 10.7 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 29.2/46.2 MB 10.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 29.5/46.2 MB 10.4 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 29.8/46.2 MB 10.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 30.6/46.2 MB 10.7 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 31.3/46.2 MB 10.9 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 31.8/46.2 MB 10.7 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 32.3/46.2 MB 10.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 33.0/46.2 MB 10.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 33.1/46.2 MB 10.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 33.7/46.2 MB 10.2 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 34.4/46.2 MB 10.6 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 34.9/46.2 MB 10.7 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 35.3/46.2 MB 10.7 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 35.7/46.2 MB 10.4 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 36.4/46.2 MB 10.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 37.1/46.2 MB 10.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 37.7/46.2 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 38.4/46.2 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 39.1/46.2 MB 12.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 39.7/46.2 MB 12.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 40.3/46.2 MB 12.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 40.7/46.2 MB 12.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 41.5/46.2 MB 12.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 41.9/46.2 MB 12.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 42.5/46.2 MB 12.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 43.0/46.2 MB 12.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 43.7/46.2 MB 12.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 44.5/46.2 MB 12.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.2/46.2 MB 12.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.7/46.2 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  46.2/46.2 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  46.2/46.2 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  46.2/46.2 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  46.2/46.2 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  46.2/46.2 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  46.2/46.2 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  46.2/46.2 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  46.2/46.2 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 46.2/46.2 MB 8.8 MB/s eta 0:00:00\n",
      "Downloading smart_open-7.0.4-py3-none-any.whl (61 kB)\n",
      "   ---------------------------------------- 0.0/61.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 61.2/61.2 kB ? eta 0:00:00\n",
      "Downloading wrapt-1.16.0-cp311-cp311-win_amd64.whl (37 kB)\n",
      "Installing collected packages: wrapt, scipy, smart-open, gensim\n",
      "Successfully installed gensim-4.3.2 scipy-1.12.0 smart-open-7.0.4 wrapt-1.16.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: d:\\ASU\\DV\\Project\\Data\\.venv\\Scripts\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pyarrow\n",
    "%pip install pandas\n",
    "%pip install nltk\n",
    "%pip install gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "\n",
    "# Read the parquet file\n",
    "parquet_file = pq.ParquetFile('../data/train.parquet')\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "df = parquet_file.read().to_pandas()\n",
    "\n",
    "df.drop(columns=['inputs', 'prediction', 'prediction_agent', 'annotation', 'annotation_agent', 'multi_label', 'explanation', 'metadata', 'status', 'metrics'], inplace=True)\n",
    "\n",
    "# Write to CSV file\n",
    "df.to_csv('../data/Covid-data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>event_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Also...and I know I keep posting this but it's...</td>\n",
       "      <td>0000c222-c1f6-46ad-9fd8-932d9bab6ebc</td>\n",
       "      <td>2020-06-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hackers are taking advantage of heightened con...</td>\n",
       "      <td>00028450-a2bc-4829-af5b-250ed6cd7786</td>\n",
       "      <td>2020-03-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You never know this COVID-19 thing is serious ...</td>\n",
       "      <td>0003108e-adee-4733-86ee-2b727075a08d</td>\n",
       "      <td>2020-03-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's a 2 hr long lineup to the billing in the ...</td>\n",
       "      <td>000348d2-236e-46bd-a85c-ec0e48e455bd</td>\n",
       "      <td>2020-03-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Today I took advantage of these gas prices and...</td>\n",
       "      <td>0005460d-7648-44f3-aee4-362a72747902</td>\n",
       "      <td>2020-07-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Also...and I know I keep posting this but it's...   \n",
       "1  Hackers are taking advantage of heightened con...   \n",
       "2  You never know this COVID-19 thing is serious ...   \n",
       "3  It's a 2 hr long lineup to the billing in the ...   \n",
       "4  Today I took advantage of these gas prices and...   \n",
       "\n",
       "                                     id event_timestamp  \n",
       "0  0000c222-c1f6-46ad-9fd8-932d9bab6ebc      2020-06-04  \n",
       "1  00028450-a2bc-4829-af5b-250ed6cd7786      2020-03-26  \n",
       "2  0003108e-adee-4733-86ee-2b727075a08d      2020-03-24  \n",
       "3  000348d2-236e-46bd-a85c-ec0e48e455bd      2020-03-13  \n",
       "4  0005460d-7648-44f3-aee4-362a72747902      2020-07-04  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/Covid-data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>event_timestamp</th>\n",
       "      <th>Text_Cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Also...and I know I keep posting this but it's...</td>\n",
       "      <td>0000c222-c1f6-46ad-9fd8-932d9bab6ebc</td>\n",
       "      <td>2020-06-04</td>\n",
       "      <td>also and i know i keep posting this but its im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hackers are taking advantage of heightened con...</td>\n",
       "      <td>00028450-a2bc-4829-af5b-250ed6cd7786</td>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>hackers are taking advantage of heightened con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You never know this COVID-19 thing is serious ...</td>\n",
       "      <td>0003108e-adee-4733-86ee-2b727075a08d</td>\n",
       "      <td>2020-03-24</td>\n",
       "      <td>you never know this covid 19 thing is serious ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's a 2 hr long lineup to the billing in the ...</td>\n",
       "      <td>000348d2-236e-46bd-a85c-ec0e48e455bd</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>its a 2 hr long lineup to the billing in the d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Today I took advantage of these gas prices and...</td>\n",
       "      <td>0005460d-7648-44f3-aee4-362a72747902</td>\n",
       "      <td>2020-07-04</td>\n",
       "      <td>today i took advantage of these gas prices and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Also...and I know I keep posting this but it's...   \n",
       "1  Hackers are taking advantage of heightened con...   \n",
       "2  You never know this COVID-19 thing is serious ...   \n",
       "3  It's a 2 hr long lineup to the billing in the ...   \n",
       "4  Today I took advantage of these gas prices and...   \n",
       "\n",
       "                                     id event_timestamp  \\\n",
       "0  0000c222-c1f6-46ad-9fd8-932d9bab6ebc      2020-06-04   \n",
       "1  00028450-a2bc-4829-af5b-250ed6cd7786      2020-03-26   \n",
       "2  0003108e-adee-4733-86ee-2b727075a08d      2020-03-24   \n",
       "3  000348d2-236e-46bd-a85c-ec0e48e455bd      2020-03-13   \n",
       "4  0005460d-7648-44f3-aee4-362a72747902      2020-07-04   \n",
       "\n",
       "                                        Text_Cleaned  \n",
       "0  also and i know i keep posting this but its im...  \n",
       "1  hackers are taking advantage of heightened con...  \n",
       "2  you never know this covid 19 thing is serious ...  \n",
       "3  its a 2 hr long lineup to the billing in the d...  \n",
       "4  today i took advantage of these gas prices and...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import preprocess\n",
    "\n",
    "data = preprocess.Preprocess_Tweets(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mithi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mithi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Function provided in the question to pre-process the text\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# stemming tool from nltk\n",
    "stemmer = PorterStemmer()\n",
    "# a mapping dictionary that help remove punctuations\n",
    "remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
    "def get_tokens(text):\n",
    "  # turn document into lowercase\n",
    "  lowers = text.lower()\n",
    "  # remove punctuations\n",
    "  no_punctuation = lowers.translate(remove_punctuation_map)\n",
    "  # tokenize document\n",
    "  tokens = nltk.word_tokenize(no_punctuation)\n",
    "  # remove stop words\n",
    "  filtered = [w for w in tokens if not w in stopwords.words('english')]\n",
    "  # stemming process\n",
    "  stemmed = []\n",
    "  for item in filtered:\n",
    "    stemmed.append(stemmer.stem(item))\n",
    "  # final unigrams\n",
    "  return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>event_timestamp</th>\n",
       "      <th>Text_Cleaned</th>\n",
       "      <th>Preprocessed_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Also...and I know I keep posting this but it's...</td>\n",
       "      <td>0000c222-c1f6-46ad-9fd8-932d9bab6ebc</td>\n",
       "      <td>2020-06-04</td>\n",
       "      <td>also and i know i keep posting this but its im...</td>\n",
       "      <td>[also, know, keep, post, import, get, suppli, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hackers are taking advantage of heightened con...</td>\n",
       "      <td>00028450-a2bc-4829-af5b-250ed6cd7786</td>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>hackers are taking advantage of heightened con...</td>\n",
       "      <td>[hacker, take, advantag, heighten, consum, anx...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You never know this COVID-19 thing is serious ...</td>\n",
       "      <td>0003108e-adee-4733-86ee-2b727075a08d</td>\n",
       "      <td>2020-03-24</td>\n",
       "      <td>you never know this covid 19 thing is serious ...</td>\n",
       "      <td>[never, know, covid, 19, thing, seriou, queue,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's a 2 hr long lineup to the billing in the ...</td>\n",
       "      <td>000348d2-236e-46bd-a85c-ec0e48e455bd</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>its a 2 hr long lineup to the billing in the d...</td>\n",
       "      <td>[2, hr, long, lineup, bill, desi, supermarket,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Today I took advantage of these gas prices and...</td>\n",
       "      <td>0005460d-7648-44f3-aee4-362a72747902</td>\n",
       "      <td>2020-07-04</td>\n",
       "      <td>today i took advantage of these gas prices and...</td>\n",
       "      <td>[today, took, advantag, ga, price, fill, motor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Also...and I know I keep posting this but it's...   \n",
       "1  Hackers are taking advantage of heightened con...   \n",
       "2  You never know this COVID-19 thing is serious ...   \n",
       "3  It's a 2 hr long lineup to the billing in the ...   \n",
       "4  Today I took advantage of these gas prices and...   \n",
       "\n",
       "                                     id event_timestamp  \\\n",
       "0  0000c222-c1f6-46ad-9fd8-932d9bab6ebc      2020-06-04   \n",
       "1  00028450-a2bc-4829-af5b-250ed6cd7786      2020-03-26   \n",
       "2  0003108e-adee-4733-86ee-2b727075a08d      2020-03-24   \n",
       "3  000348d2-236e-46bd-a85c-ec0e48e455bd      2020-03-13   \n",
       "4  0005460d-7648-44f3-aee4-362a72747902      2020-07-04   \n",
       "\n",
       "                                        Text_Cleaned  \\\n",
       "0  also and i know i keep posting this but its im...   \n",
       "1  hackers are taking advantage of heightened con...   \n",
       "2  you never know this covid 19 thing is serious ...   \n",
       "3  its a 2 hr long lineup to the billing in the d...   \n",
       "4  today i took advantage of these gas prices and...   \n",
       "\n",
       "                                   Preprocessed_Text  \n",
       "0  [also, know, keep, post, import, get, suppli, ...  \n",
       "1  [hacker, take, advantag, heighten, consum, anx...  \n",
       "2  [never, know, covid, 19, thing, seriou, queue,...  \n",
       "3  [2, hr, long, lineup, bill, desi, supermarket,...  \n",
       "4  [today, took, advantag, ga, price, fill, motor...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Preprocessed_Text'] = data['Text_Cleaned'].apply(get_tokens)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/dictionary.txt','r') as f:\n",
    "  dictionary_words = set()\n",
    "  for line in f:\n",
    "    dictionary_words.add(line.strip()) #Removing the extra spaces incase it is present\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionary_filter(text_to_be_filtered):\n",
    "    filtered_words = []\n",
    "    for word in text_to_be_filtered:\n",
    "        if(word in dictionary_words):\n",
    "            filtered_words.append(word)\n",
    "\n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Preprocessed_Text'] = data['Preprocessed_Text'].apply(dictionary_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>event_timestamp</th>\n",
       "      <th>Text_Cleaned</th>\n",
       "      <th>Preprocessed_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Also...and I know I keep posting this but it's...</td>\n",
       "      <td>0000c222-c1f6-46ad-9fd8-932d9bab6ebc</td>\n",
       "      <td>2020-06-04</td>\n",
       "      <td>also and i know i keep posting this but its im...</td>\n",
       "      <td>also,know,keep,post,import,get,onlin,store,one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hackers are taking advantage of heightened con...</td>\n",
       "      <td>00028450-a2bc-4829-af5b-250ed6cd7786</td>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>hackers are taking advantage of heightened con...</td>\n",
       "      <td>take,consum,target,user,email,campaign,send,li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You never know this COVID-19 thing is serious ...</td>\n",
       "      <td>0003108e-adee-4733-86ee-2b727075a08d</td>\n",
       "      <td>2020-03-24</td>\n",
       "      <td>you never know this covid 19 thing is serious ...</td>\n",
       "      <td>never,know,thing,seriou,outsid,get,lot,10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's a 2 hr long lineup to the billing in the ...</td>\n",
       "      <td>000348d2-236e-46bd-a85c-ec0e48e455bd</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>its a 2 hr long lineup to the billing in the d...</td>\n",
       "      <td>2,long,bill,peopl,get,hand,see,concern,face,da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Today I took advantage of these gas prices and...</td>\n",
       "      <td>0005460d-7648-44f3-aee4-362a72747902</td>\n",
       "      <td>2020-07-04</td>\n",
       "      <td>today i took advantage of these gas prices and...</td>\n",
       "      <td>today,took,price,never,given,mani,look,life,he...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Also...and I know I keep posting this but it's...   \n",
       "1  Hackers are taking advantage of heightened con...   \n",
       "2  You never know this COVID-19 thing is serious ...   \n",
       "3  It's a 2 hr long lineup to the billing in the ...   \n",
       "4  Today I took advantage of these gas prices and...   \n",
       "\n",
       "                                     id event_timestamp  \\\n",
       "0  0000c222-c1f6-46ad-9fd8-932d9bab6ebc      2020-06-04   \n",
       "1  00028450-a2bc-4829-af5b-250ed6cd7786      2020-03-26   \n",
       "2  0003108e-adee-4733-86ee-2b727075a08d      2020-03-24   \n",
       "3  000348d2-236e-46bd-a85c-ec0e48e455bd      2020-03-13   \n",
       "4  0005460d-7648-44f3-aee4-362a72747902      2020-07-04   \n",
       "\n",
       "                                        Text_Cleaned  \\\n",
       "0  also and i know i keep posting this but its im...   \n",
       "1  hackers are taking advantage of heightened con...   \n",
       "2  you never know this covid 19 thing is serious ...   \n",
       "3  its a 2 hr long lineup to the billing in the d...   \n",
       "4  today i took advantage of these gas prices and...   \n",
       "\n",
       "                                   Preprocessed_Text  \n",
       "0  also,know,keep,post,import,get,onlin,store,one...  \n",
       "1  take,consum,target,user,email,campaign,send,li...  \n",
       "2          never,know,thing,seriou,outsid,get,lot,10  \n",
       "3  2,long,bill,peopl,get,hand,see,concern,face,da...  \n",
       "4  today,took,price,never,given,mani,look,life,he...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Preprocessed_Text'] = data['Preprocessed_Text'].apply(lambda x: ','.join(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the text\n",
    "data['Preprocessed_Text'] = data['Preprocessed_Text'].apply(lambda x: simple_preprocess(x))\n",
    "\n",
    "# Create a dictionary and corpus\n",
    "dictionary = Dictionary(data['Preprocessed_Text'])\n",
    "corpus = [dictionary.doc2bow(text) for text in data['Preprocessed_Text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: 0.148*\"store\" + 0.076*\"worker\" + 0.037*\"work\" + 0.030*\"close\" + 0.029*\"retail\" + 0.026*\"hour\" + 0.025*\"line\" + 0.024*\"peopl\" + 0.024*\"open\" + 0.018*\"custom\"\n",
      "Topic 1: 0.073*\"peopl\" + 0.064*\"buy\" + 0.041*\"need\" + 0.028*\"stop\" + 0.026*\"make\" + 0.023*\"stock\" + 0.019*\"help\" + 0.018*\"bank\" + 0.018*\"get\" + 0.017*\"sell\"\n",
      "Topic 2: 0.035*\"state\" + 0.030*\"global\" + 0.026*\"countri\" + 0.025*\"million\" + 0.023*\"consum\" + 0.021*\"world\" + 0.019*\"china\" + 0.017*\"american\" + 0.017*\"economi\" + 0.016*\"nation\"\n",
      "Topic 3: 0.074*\"hand\" + 0.039*\"protect\" + 0.039*\"consum\" + 0.032*\"test\" + 0.032*\"health\" + 0.028*\"use\" + 0.026*\"care\" + 0.021*\"report\" + 0.020*\"face\" + 0.018*\"fight\"\n",
      "Topic 4: 0.135*\"onlin\" + 0.044*\"order\" + 0.029*\"dollar\" + 0.022*\"avail\" + 0.019*\"local\" + 0.018*\"free\" + 0.018*\"deliv\" + 0.017*\"via\" + 0.015*\"pick\" + 0.014*\"limit\"\n",
      "Topic 5: 0.079*\"consum\" + 0.042*\"demand\" + 0.042*\"busi\" + 0.027*\"chang\" + 0.026*\"impact\" + 0.021*\"new\" + 0.017*\"product\" + 0.017*\"compani\" + 0.016*\"help\" + 0.016*\"continu\"\n",
      "Topic 6: 0.077*\"go\" + 0.055*\"store\" + 0.036*\"get\" + 0.036*\"like\" + 0.031*\"peopl\" + 0.031*\"paper\" + 0.020*\"know\" + 0.019*\"need\" + 0.016*\"still\" + 0.016*\"work\"\n",
      "Topic 7: 0.256*\"price\" + 0.044*\"oil\" + 0.038*\"market\" + 0.026*\"low\" + 0.023*\"increas\" + 0.021*\"demand\" + 0.018*\"due\" + 0.018*\"drop\" + 0.017*\"produc\" + 0.016*\"fall\"\n",
      "Topic 8: 0.114*\"home\" + 0.080*\"stay\" + 0.024*\"avoid\" + 0.023*\"inform\" + 0.023*\"keep\" + 0.022*\"best\" + 0.022*\"work\" + 0.021*\"visit\" + 0.020*\"help\" + 0.019*\"right\"\n",
      "Topic 9: 0.068*\"week\" + 0.049*\"stock\" + 0.046*\"day\" + 0.031*\"last\" + 0.027*\"case\" + 0.026*\"month\" + 0.024*\"next\" + 0.023*\"two\" + 0.020*\"one\" + 0.019*\"year\"\n"
     ]
    }
   ],
   "source": [
    "# Train the LDA model\n",
    "number_of_topics = 10\n",
    "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=number_of_topics, passes=10, random_state=42)\n",
    "\n",
    "# Print the generated topics\n",
    "for idx, topic in lda_model.print_topics():\n",
    "    print(f'Topic {idx}: {topic}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the topic distribution for each document\n",
    "topic_results = [lda_model.get_document_topics(item) for item in corpus]\n",
    "\n",
    "# Extract the dominant topic for each document\n",
    "dominant_topics = [(doc_id, max(topics, key=lambda x: x[1])[0]) for doc_id, topics in enumerate(topic_results)]\n",
    "\n",
    "# Create a dataframe to store the document ID and dominant topic\n",
    "dominant_topics_df = pd.DataFrame(dominant_topics, columns=['id', 'Topic'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.concat([data, dominant_topics_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>event_timestamp</th>\n",
       "      <th>Text_Cleaned</th>\n",
       "      <th>Preprocessed_Text</th>\n",
       "      <th>id</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Also...and I know I keep posting this but it's...</td>\n",
       "      <td>0000c222-c1f6-46ad-9fd8-932d9bab6ebc</td>\n",
       "      <td>2020-06-04</td>\n",
       "      <td>also and i know i keep posting this but its im...</td>\n",
       "      <td>[also, know, keep, post, import, get, onlin, s...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hackers are taking advantage of heightened con...</td>\n",
       "      <td>00028450-a2bc-4829-af5b-250ed6cd7786</td>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>hackers are taking advantage of heightened con...</td>\n",
       "      <td>[take, consum, target, user, email, campaign, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You never know this COVID-19 thing is serious ...</td>\n",
       "      <td>0003108e-adee-4733-86ee-2b727075a08d</td>\n",
       "      <td>2020-03-24</td>\n",
       "      <td>you never know this covid 19 thing is serious ...</td>\n",
       "      <td>[never, know, thing, seriou, outsid, get, lot]</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's a 2 hr long lineup to the billing in the ...</td>\n",
       "      <td>000348d2-236e-46bd-a85c-ec0e48e455bd</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>its a 2 hr long lineup to the billing in the d...</td>\n",
       "      <td>[long, bill, peopl, get, hand, see, concern, f...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Today I took advantage of these gas prices and...</td>\n",
       "      <td>0005460d-7648-44f3-aee4-362a72747902</td>\n",
       "      <td>2020-07-04</td>\n",
       "      <td>today i took advantage of these gas prices and...</td>\n",
       "      <td>[today, took, price, never, given, mani, look,...</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Also...and I know I keep posting this but it's...   \n",
       "1  Hackers are taking advantage of heightened con...   \n",
       "2  You never know this COVID-19 thing is serious ...   \n",
       "3  It's a 2 hr long lineup to the billing in the ...   \n",
       "4  Today I took advantage of these gas prices and...   \n",
       "\n",
       "                                     id event_timestamp  \\\n",
       "0  0000c222-c1f6-46ad-9fd8-932d9bab6ebc      2020-06-04   \n",
       "1  00028450-a2bc-4829-af5b-250ed6cd7786      2020-03-26   \n",
       "2  0003108e-adee-4733-86ee-2b727075a08d      2020-03-24   \n",
       "3  000348d2-236e-46bd-a85c-ec0e48e455bd      2020-03-13   \n",
       "4  0005460d-7648-44f3-aee4-362a72747902      2020-07-04   \n",
       "\n",
       "                                        Text_Cleaned  \\\n",
       "0  also and i know i keep posting this but its im...   \n",
       "1  hackers are taking advantage of heightened con...   \n",
       "2  you never know this covid 19 thing is serious ...   \n",
       "3  its a 2 hr long lineup to the billing in the d...   \n",
       "4  today i took advantage of these gas prices and...   \n",
       "\n",
       "                                   Preprocessed_Text  id  Topic  \n",
       "0  [also, know, keep, post, import, get, onlin, s...   0      1  \n",
       "1  [take, consum, target, user, email, campaign, ...   1      8  \n",
       "2     [never, know, thing, seriou, outsid, get, lot]   2      6  \n",
       "3  [long, bill, peopl, get, hand, see, concern, f...   3      6  \n",
       "4  [today, took, price, never, given, mani, look,...   4      9  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-topic    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "Start\n",
      "Topic 0:\n",
      "Sub - Topic 0: 0.127*\"worker\" + 0.068*\"store\" + 0.045*\"work\" + 0.022*\"peopl\" + 0.019*\"us\" + 0.017*\"die\" + 0.015*\"keep\" + 0.015*\"help\" + 0.014*\"risk\" + 0.014*\"everyon\"\n",
      "Sub - Topic 1: 0.074*\"store\" + 0.037*\"custom\" + 0.035*\"peopl\" + 0.033*\"time\" + 0.026*\"line\" + 0.023*\"one\" + 0.020*\"get\" + 0.018*\"local\" + 0.018*\"wait\" + 0.016*\"limit\"\n",
      "Sub - Topic 2: 0.102*\"store\" + 0.050*\"hour\" + 0.046*\"close\" + 0.041*\"retail\" + 0.035*\"open\" + 0.020*\"onlin\" + 0.013*\"day\" + 0.012*\"leav\" + 0.012*\"due\" + 0.011*\"servic\"\n",
      "End\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "Start\n",
      "Topic 1:\n",
      "Sub - Topic 0: 0.036*\"price\" + 0.030*\"need\" + 0.027*\"peopl\" + 0.023*\"take\" + 0.022*\"stock\" + 0.018*\"get\" + 0.015*\"stop\" + 0.014*\"would\" + 0.014*\"world\" + 0.012*\"happen\"\n",
      "Sub - Topic 1: 0.083*\"buy\" + 0.072*\"peopl\" + 0.025*\"stop\" + 0.025*\"need\" + 0.019*\"think\" + 0.017*\"time\" + 0.015*\"store\" + 0.015*\"stock\" + 0.012*\"everyon\" + 0.012*\"say\"\n",
      "Sub - Topic 2: 0.040*\"help\" + 0.034*\"make\" + 0.030*\"us\" + 0.027*\"price\" + 0.025*\"need\" + 0.019*\"peopl\" + 0.019*\"sell\" + 0.018*\"bank\" + 0.017*\"get\" + 0.017*\"time\"\n",
      "End\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "Start\n",
      "Topic 2:\n",
      "Sub - Topic 0: 0.058*\"price\" + 0.017*\"oil\" + 0.016*\"economi\" + 0.016*\"global\" + 0.013*\"put\" + 0.012*\"consum\" + 0.012*\"like\" + 0.011*\"american\" + 0.010*\"econom\" + 0.010*\"presid\"\n",
      "Sub - Topic 1: 0.030*\"price\" + 0.027*\"million\" + 0.025*\"state\" + 0.024*\"dollar\" + 0.017*\"hit\" + 0.017*\"viru\" + 0.015*\"consum\" + 0.012*\"home\" + 0.012*\"emerg\" + 0.012*\"billion\"\n",
      "Sub - Topic 2: 0.043*\"consum\" + 0.026*\"world\" + 0.026*\"china\" + 0.022*\"say\" + 0.021*\"price\" + 0.018*\"drive\" + 0.018*\"countri\" + 0.017*\"report\" + 0.016*\"buy\" + 0.015*\"us\"\n",
      "End\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "Start\n",
      "Topic 3:\n",
      "Sub - Topic 0: 0.145*\"hand\" + 0.057*\"use\" + 0.038*\"make\" + 0.023*\"face\" + 0.014*\"fight\" + 0.014*\"import\" + 0.013*\"need\" + 0.013*\"base\" + 0.012*\"stay\" + 0.011*\"help\"\n",
      "Sub - Topic 1: 0.056*\"consum\" + 0.055*\"price\" + 0.032*\"report\" + 0.027*\"protect\" + 0.016*\"compani\" + 0.015*\"test\" + 0.014*\"product\" + 0.014*\"drug\" + 0.012*\"public\" + 0.011*\"warn\"\n",
      "Sub - Topic 2: 0.033*\"consum\" + 0.033*\"health\" + 0.023*\"test\" + 0.017*\"store\" + 0.017*\"care\" + 0.016*\"provid\" + 0.015*\"worker\" + 0.015*\"help\" + 0.014*\"protect\" + 0.012*\"question\"\n",
      "End\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "Start\n",
      "Topic 4:\n",
      "Sub - Topic 0: 0.054*\"onlin\" + 0.033*\"need\" + 0.027*\"help\" + 0.026*\"order\" + 0.025*\"price\" + 0.025*\"well\" + 0.020*\"custom\" + 0.015*\"time\" + 0.015*\"system\" + 0.015*\"use\"\n",
      "Sub - Topic 1: 0.046*\"onlin\" + 0.042*\"dollar\" + 0.021*\"order\" + 0.020*\"price\" + 0.016*\"due\" + 0.015*\"avail\" + 0.014*\"free\" + 0.013*\"store\" + 0.011*\"go\" + 0.011*\"via\"\n",
      "Sub - Topic 2: 0.098*\"onlin\" + 0.026*\"local\" + 0.024*\"support\" + 0.021*\"store\" + 0.018*\"get\" + 0.017*\"deliv\" + 0.015*\"use\" + 0.015*\"way\" + 0.015*\"time\" + 0.013*\"free\"\n",
      "End\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "Start\n",
      "Topic 5:\n",
      "Sub - Topic 0: 0.066*\"demand\" + 0.028*\"help\" + 0.025*\"increas\" + 0.024*\"product\" + 0.022*\"servic\" + 0.020*\"due\" + 0.016*\"meet\" + 0.016*\"keep\" + 0.015*\"commun\" + 0.015*\"store\"\n",
      "Sub - Topic 1: 0.123*\"consum\" + 0.035*\"impact\" + 0.031*\"chang\" + 0.021*\"busi\" + 0.019*\"market\" + 0.014*\"brand\" + 0.012*\"data\" + 0.011*\"retail\" + 0.010*\"industri\" + 0.010*\"read\"\n",
      "Sub - Topic 2: 0.044*\"new\" + 0.029*\"onlin\" + 0.027*\"busi\" + 0.025*\"price\" + 0.014*\"time\" + 0.014*\"plan\" + 0.011*\"compani\" + 0.011*\"term\" + 0.011*\"small\" + 0.011*\"like\"\n",
      "End\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "Start\n",
      "Topic 6:\n",
      "Sub - Topic 0: 0.068*\"paper\" + 0.046*\"stock\" + 0.041*\"buy\" + 0.039*\"get\" + 0.028*\"hand\" + 0.024*\"find\" + 0.021*\"run\" + 0.018*\"need\" + 0.016*\"want\" + 0.016*\"go\"\n",
      "Sub - Topic 1: 0.087*\"store\" + 0.051*\"go\" + 0.035*\"like\" + 0.034*\"peopl\" + 0.023*\"get\" + 0.019*\"went\" + 0.019*\"need\" + 0.018*\"today\" + 0.017*\"day\" + 0.016*\"look\"\n",
      "Sub - Topic 2: 0.041*\"go\" + 0.030*\"price\" + 0.028*\"know\" + 0.025*\"work\" + 0.024*\"see\" + 0.023*\"peopl\" + 0.018*\"store\" + 0.014*\"onlin\" + 0.014*\"get\" + 0.014*\"even\"\n",
      "End\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "Start\n",
      "Topic 7:\n",
      "Sub - Topic 0: 0.110*\"price\" + 0.059*\"market\" + 0.017*\"report\" + 0.016*\"could\" + 0.015*\"rise\" + 0.015*\"due\" + 0.014*\"global\" + 0.014*\"stock\" + 0.012*\"demand\" + 0.012*\"drop\"\n",
      "Sub - Topic 1: 0.108*\"price\" + 0.095*\"oil\" + 0.023*\"cut\" + 0.021*\"fall\" + 0.019*\"demand\" + 0.017*\"us\" + 0.015*\"produc\" + 0.012*\"russia\" + 0.012*\"war\" + 0.011*\"due\"\n",
      "Sub - Topic 2: 0.132*\"price\" + 0.034*\"low\" + 0.029*\"increas\" + 0.018*\"time\" + 0.015*\"peopl\" + 0.014*\"product\" + 0.014*\"demand\" + 0.014*\"profit\" + 0.012*\"due\" + 0.012*\"higher\"\n",
      "End\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "Start\n",
      "Topic 8:\n",
      "Sub - Topic 0: 0.035*\"help\" + 0.034*\"price\" + 0.027*\"travel\" + 0.024*\"consum\" + 0.021*\"best\" + 0.020*\"link\" + 0.018*\"websit\" + 0.017*\"home\" + 0.016*\"email\" + 0.016*\"offic\"\n",
      "Sub - Topic 1: 0.076*\"stay\" + 0.069*\"home\" + 0.036*\"work\" + 0.035*\"keep\" + 0.027*\"onlin\" + 0.022*\"us\" + 0.016*\"go\" + 0.014*\"get\" + 0.013*\"must\" + 0.012*\"help\"\n",
      "Sub - Topic 2: 0.045*\"right\" + 0.040*\"avoid\" + 0.036*\"inform\" + 0.030*\"time\" + 0.020*\"onlin\" + 0.018*\"consum\" + 0.017*\"take\" + 0.016*\"work\" + 0.016*\"everyon\" + 0.015*\"list\"\n",
      "End\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "Start\n",
      "Topic 9:\n",
      "Sub - Topic 0: 0.055*\"week\" + 0.026*\"one\" + 0.025*\"day\" + 0.024*\"two\" + 0.020*\"store\" + 0.020*\"price\" + 0.015*\"stock\" + 0.015*\"case\" + 0.013*\"last\" + 0.011*\"new\"\n",
      "Sub - Topic 1: 0.051*\"stock\" + 0.027*\"year\" + 0.020*\"price\" + 0.016*\"store\" + 0.016*\"day\" + 0.014*\"next\" + 0.014*\"week\" + 0.013*\"last\" + 0.013*\"month\" + 0.012*\"home\"\n",
      "Sub - Topic 2: 0.032*\"day\" + 0.031*\"time\" + 0.018*\"case\" + 0.017*\"last\" + 0.016*\"stock\" + 0.016*\"uk\" + 0.014*\"price\" + 0.013*\"death\" + 0.011*\"life\" + 0.011*\"today\"\n",
      "End\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Add a new column for the subtopic in the merged_data DataFrame\n",
    "merged_data['Sub-Topic'] = -1\n",
    "\n",
    "for topic in range(number_of_topics):\n",
    "    print(\"---------------------------------------------\")\n",
    "    print(\"Start\")\n",
    "    print(f'Topic {topic}:')\n",
    "    input_df = merged_data[merged_data['Topic'] == topic]\n",
    "\n",
    "    # Create a dictionary and corpus\n",
    "    dictionary = Dictionary(input_df['Preprocessed_Text'])\n",
    "    corpus = [dictionary.doc2bow(text) for text in input_df['Preprocessed_Text']]\n",
    "\n",
    "    # Train the LDA model\n",
    "    number_of_sub_topics = 3\n",
    "    lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=number_of_sub_topics, passes=10, random_state=42)\n",
    "\n",
    "    # Print the generated topics\n",
    "    for idx, sub_topic in lda_model.print_topics():\n",
    "        print(f'Sub - Topic {idx}: {sub_topic}')\n",
    "\n",
    "    # Assign the subtopic with the highest probability to each document\n",
    "    for i, row in input_df.iterrows():\n",
    "        bow = dictionary.doc2bow(row['Preprocessed_Text'])\n",
    "        subtopic_distribution = lda_model[bow]\n",
    "        # Choose the subtopic with the highest probability\n",
    "        subtopic = max(subtopic_distribution, key=lambda x: x[1])[0]\n",
    "        merged_data.loc[i, 'Sub-Topic'] = subtopic\n",
    "\n",
    "    print(\"End\")\n",
    "    print(\"---------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>event_timestamp</th>\n",
       "      <th>Text_Cleaned</th>\n",
       "      <th>Preprocessed_Text</th>\n",
       "      <th>id</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Sub-Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Also...and I know I keep posting this but it's...</td>\n",
       "      <td>0000c222-c1f6-46ad-9fd8-932d9bab6ebc</td>\n",
       "      <td>2020-06-04</td>\n",
       "      <td>also and i know i keep posting this but its im...</td>\n",
       "      <td>[also, know, keep, post, import, get, onlin, s...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hackers are taking advantage of heightened con...</td>\n",
       "      <td>00028450-a2bc-4829-af5b-250ed6cd7786</td>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>hackers are taking advantage of heightened con...</td>\n",
       "      <td>[take, consum, target, user, email, campaign, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You never know this COVID-19 thing is serious ...</td>\n",
       "      <td>0003108e-adee-4733-86ee-2b727075a08d</td>\n",
       "      <td>2020-03-24</td>\n",
       "      <td>you never know this covid 19 thing is serious ...</td>\n",
       "      <td>[never, know, thing, seriou, outsid, get, lot]</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's a 2 hr long lineup to the billing in the ...</td>\n",
       "      <td>000348d2-236e-46bd-a85c-ec0e48e455bd</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>its a 2 hr long lineup to the billing in the d...</td>\n",
       "      <td>[long, bill, peopl, get, hand, see, concern, f...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Today I took advantage of these gas prices and...</td>\n",
       "      <td>0005460d-7648-44f3-aee4-362a72747902</td>\n",
       "      <td>2020-07-04</td>\n",
       "      <td>today i took advantage of these gas prices and...</td>\n",
       "      <td>[today, took, price, never, given, mani, look,...</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Also...and I know I keep posting this but it's...   \n",
       "1  Hackers are taking advantage of heightened con...   \n",
       "2  You never know this COVID-19 thing is serious ...   \n",
       "3  It's a 2 hr long lineup to the billing in the ...   \n",
       "4  Today I took advantage of these gas prices and...   \n",
       "\n",
       "                                     id event_timestamp  \\\n",
       "0  0000c222-c1f6-46ad-9fd8-932d9bab6ebc      2020-06-04   \n",
       "1  00028450-a2bc-4829-af5b-250ed6cd7786      2020-03-26   \n",
       "2  0003108e-adee-4733-86ee-2b727075a08d      2020-03-24   \n",
       "3  000348d2-236e-46bd-a85c-ec0e48e455bd      2020-03-13   \n",
       "4  0005460d-7648-44f3-aee4-362a72747902      2020-07-04   \n",
       "\n",
       "                                        Text_Cleaned  \\\n",
       "0  also and i know i keep posting this but its im...   \n",
       "1  hackers are taking advantage of heightened con...   \n",
       "2  you never know this covid 19 thing is serious ...   \n",
       "3  its a 2 hr long lineup to the billing in the d...   \n",
       "4  today i took advantage of these gas prices and...   \n",
       "\n",
       "                                   Preprocessed_Text  id  Topic  Sub-Topic  \n",
       "0  [also, know, keep, post, import, get, onlin, s...   0      1          2  \n",
       "1  [take, consum, target, user, email, campaign, ...   1      8          2  \n",
       "2     [never, know, thing, seriou, outsid, get, lot]   2      6          2  \n",
       "3  [long, bill, peopl, get, hand, see, concern, f...   3      6          2  \n",
       "4  [today, took, price, never, given, mani, look,...   4      9          2  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>event_timestamp</th>\n",
       "      <th>Text_Cleaned</th>\n",
       "      <th>Preprocessed_Text</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Sub-Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Also...and I know I keep posting this but it's...</td>\n",
       "      <td>2020-06-04</td>\n",
       "      <td>also and i know i keep posting this but its im...</td>\n",
       "      <td>[also, know, keep, post, import, get, onlin, s...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hackers are taking advantage of heightened con...</td>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>hackers are taking advantage of heightened con...</td>\n",
       "      <td>[take, consum, target, user, email, campaign, ...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You never know this COVID-19 thing is serious ...</td>\n",
       "      <td>2020-03-24</td>\n",
       "      <td>you never know this covid 19 thing is serious ...</td>\n",
       "      <td>[never, know, thing, seriou, outsid, get, lot]</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's a 2 hr long lineup to the billing in the ...</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>its a 2 hr long lineup to the billing in the d...</td>\n",
       "      <td>[long, bill, peopl, get, hand, see, concern, f...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Today I took advantage of these gas prices and...</td>\n",
       "      <td>2020-07-04</td>\n",
       "      <td>today i took advantage of these gas prices and...</td>\n",
       "      <td>[today, took, price, never, given, mani, look,...</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text event_timestamp  \\\n",
       "0  Also...and I know I keep posting this but it's...      2020-06-04   \n",
       "1  Hackers are taking advantage of heightened con...      2020-03-26   \n",
       "2  You never know this COVID-19 thing is serious ...      2020-03-24   \n",
       "3  It's a 2 hr long lineup to the billing in the ...      2020-03-13   \n",
       "4  Today I took advantage of these gas prices and...      2020-07-04   \n",
       "\n",
       "                                        Text_Cleaned  \\\n",
       "0  also and i know i keep posting this but its im...   \n",
       "1  hackers are taking advantage of heightened con...   \n",
       "2  you never know this covid 19 thing is serious ...   \n",
       "3  its a 2 hr long lineup to the billing in the d...   \n",
       "4  today i took advantage of these gas prices and...   \n",
       "\n",
       "                                   Preprocessed_Text  Topic  Sub-Topic  \n",
       "0  [also, know, keep, post, import, get, onlin, s...      1          2  \n",
       "1  [take, consum, target, user, email, campaign, ...      8          2  \n",
       "2     [never, know, thing, seriou, outsid, get, lot]      6          2  \n",
       "3  [long, bill, peopl, get, hand, see, concern, f...      6          2  \n",
       "4  [today, took, price, never, given, mani, look,...      9          2  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.drop(columns=['id'], inplace=True)\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.to_csv('../data/Covid-data-with-topic-num.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>event_timestamp</th>\n",
       "      <th>Text_Cleaned</th>\n",
       "      <th>Preprocessed_Text</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Sub-Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Also...and I know I keep posting this but it's...</td>\n",
       "      <td>2020-06-04</td>\n",
       "      <td>also and i know i keep posting this but its im...</td>\n",
       "      <td>['also', 'know', 'keep', 'post', 'import', 'ge...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hackers are taking advantage of heightened con...</td>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>hackers are taking advantage of heightened con...</td>\n",
       "      <td>['take', 'consum', 'target', 'user', 'email', ...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You never know this COVID-19 thing is serious ...</td>\n",
       "      <td>2020-03-24</td>\n",
       "      <td>you never know this covid 19 thing is serious ...</td>\n",
       "      <td>['never', 'know', 'thing', 'seriou', 'outsid',...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's a 2 hr long lineup to the billing in the ...</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>its a 2 hr long lineup to the billing in the d...</td>\n",
       "      <td>['long', 'bill', 'peopl', 'get', 'hand', 'see'...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Today I took advantage of these gas prices and...</td>\n",
       "      <td>2020-07-04</td>\n",
       "      <td>today i took advantage of these gas prices and...</td>\n",
       "      <td>['today', 'took', 'price', 'never', 'given', '...</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text event_timestamp  \\\n",
       "0  Also...and I know I keep posting this but it's...      2020-06-04   \n",
       "1  Hackers are taking advantage of heightened con...      2020-03-26   \n",
       "2  You never know this COVID-19 thing is serious ...      2020-03-24   \n",
       "3  It's a 2 hr long lineup to the billing in the ...      2020-03-13   \n",
       "4  Today I took advantage of these gas prices and...      2020-07-04   \n",
       "\n",
       "                                        Text_Cleaned  \\\n",
       "0  also and i know i keep posting this but its im...   \n",
       "1  hackers are taking advantage of heightened con...   \n",
       "2  you never know this covid 19 thing is serious ...   \n",
       "3  its a 2 hr long lineup to the billing in the d...   \n",
       "4  today i took advantage of these gas prices and...   \n",
       "\n",
       "                                   Preprocessed_Text  Topic  Sub-Topic  \n",
       "0  ['also', 'know', 'keep', 'post', 'import', 'ge...      1          2  \n",
       "1  ['take', 'consum', 'target', 'user', 'email', ...      8          2  \n",
       "2  ['never', 'know', 'thing', 'seriou', 'outsid',...      6          2  \n",
       "3  ['long', 'bill', 'peopl', 'get', 'hand', 'see'...      6          2  \n",
       "4  ['today', 'took', 'price', 'never', 'given', '...      9          2  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "merged_data = pd.read_csv('../data/Covid-data-with-topic-num.csv')\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_mapping = {\n",
    "    0: 'Store',\n",
    "    1: 'Shopping Behavior',\n",
    "    2: 'Global Economy',\n",
    "    3: 'Health Measures',\n",
    "    4: 'Online Shopping',\n",
    "    5: 'Consumer Impact',\n",
    "    6: 'Store Visits',\n",
    "    7: 'Oil Market',\n",
    "    8: 'Stay Home',\n",
    "    9: 'Time Periods'\n",
    "}\n",
    "\n",
    "subtopic_mapping = {\n",
    "    0: {\n",
    "        0: 'Worker Safety',\n",
    "        1: 'Customer Waiting',\n",
    "        2: 'Store Operations'\n",
    "    },\n",
    "    1: {\n",
    "        0: 'Price Fluctuations',\n",
    "        1: 'Buying Trends',\n",
    "        2: 'Financial Assistance'\n",
    "    },\n",
    "    2: {\n",
    "        0: 'Market Prices',\n",
    "        1: 'Economic Impact',\n",
    "        2: 'Consumer Behavior'\n",
    "    },\n",
    "    3: {\n",
    "        0: 'Hand Hygiene',\n",
    "        1: 'Health Reports',\n",
    "        2: 'Healthcare Services'\n",
    "    },\n",
    "    4: {\n",
    "        0: 'Online Orders',\n",
    "        1: 'Order Pricing',\n",
    "        2: 'Local Support'\n",
    "    },\n",
    "    5: {\n",
    "        0: 'Demand Changes',\n",
    "        1: 'Market Impact',\n",
    "        2: 'Business Response'\n",
    "    },\n",
    "    6: {\n",
    "        0: 'Paper Purchases',\n",
    "        1: 'In-store Visits',\n",
    "        2: 'Price Awareness'\n",
    "    },\n",
    "    7: {\n",
    "        0: 'Price Volatility',\n",
    "        1: 'Oil Market Impact',\n",
    "        2: 'Price Trends'\n",
    "    },\n",
    "    8: {\n",
    "        0: 'Home Safety',\n",
    "        1: 'Stay-at-home Measures',\n",
    "        2: 'Information Sources'\n",
    "    },\n",
    "    9: {\n",
    "        0: 'Weekly Trends',\n",
    "        1: 'Stock Market Activity',\n",
    "        2: 'Daily Reports'\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the numeric values with the corresponding topic names\n",
    "merged_data['Topic_'] = merged_data['Topic'].replace(topic_mapping)\n",
    "\n",
    "# Replace the numeric values with the corresponding subtopic names based on their topics\n",
    "merged_data['Sub-Topic_'] = merged_data.apply(lambda row: subtopic_mapping[row['Topic']][row['Sub-Topic']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>event_timestamp</th>\n",
       "      <th>Text_Cleaned</th>\n",
       "      <th>Preprocessed_Text</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Sub-Topic</th>\n",
       "      <th>Topic_</th>\n",
       "      <th>Sub-Topic_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Also...and I know I keep posting this but it's...</td>\n",
       "      <td>2020-06-04</td>\n",
       "      <td>also and i know i keep posting this but its im...</td>\n",
       "      <td>['also', 'know', 'keep', 'post', 'import', 'ge...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Shopping Behavior</td>\n",
       "      <td>Financial Assistance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hackers are taking advantage of heightened con...</td>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>hackers are taking advantage of heightened con...</td>\n",
       "      <td>['take', 'consum', 'target', 'user', 'email', ...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>Stay Home</td>\n",
       "      <td>Information Sources</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You never know this COVID-19 thing is serious ...</td>\n",
       "      <td>2020-03-24</td>\n",
       "      <td>you never know this covid 19 thing is serious ...</td>\n",
       "      <td>['never', 'know', 'thing', 'seriou', 'outsid',...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>Store Visits</td>\n",
       "      <td>Price Awareness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's a 2 hr long lineup to the billing in the ...</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>its a 2 hr long lineup to the billing in the d...</td>\n",
       "      <td>['long', 'bill', 'peopl', 'get', 'hand', 'see'...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>Store Visits</td>\n",
       "      <td>Price Awareness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Today I took advantage of these gas prices and...</td>\n",
       "      <td>2020-07-04</td>\n",
       "      <td>today i took advantage of these gas prices and...</td>\n",
       "      <td>['today', 'took', 'price', 'never', 'given', '...</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>Time Periods</td>\n",
       "      <td>Daily Reports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text event_timestamp  \\\n",
       "0  Also...and I know I keep posting this but it's...      2020-06-04   \n",
       "1  Hackers are taking advantage of heightened con...      2020-03-26   \n",
       "2  You never know this COVID-19 thing is serious ...      2020-03-24   \n",
       "3  It's a 2 hr long lineup to the billing in the ...      2020-03-13   \n",
       "4  Today I took advantage of these gas prices and...      2020-07-04   \n",
       "\n",
       "                                        Text_Cleaned  \\\n",
       "0  also and i know i keep posting this but its im...   \n",
       "1  hackers are taking advantage of heightened con...   \n",
       "2  you never know this covid 19 thing is serious ...   \n",
       "3  its a 2 hr long lineup to the billing in the d...   \n",
       "4  today i took advantage of these gas prices and...   \n",
       "\n",
       "                                   Preprocessed_Text  Topic  Sub-Topic  \\\n",
       "0  ['also', 'know', 'keep', 'post', 'import', 'ge...      1          2   \n",
       "1  ['take', 'consum', 'target', 'user', 'email', ...      8          2   \n",
       "2  ['never', 'know', 'thing', 'seriou', 'outsid',...      6          2   \n",
       "3  ['long', 'bill', 'peopl', 'get', 'hand', 'see'...      6          2   \n",
       "4  ['today', 'took', 'price', 'never', 'given', '...      9          2   \n",
       "\n",
       "              Topic_            Sub-Topic_  \n",
       "0  Shopping Behavior  Financial Assistance  \n",
       "1          Stay Home   Information Sources  \n",
       "2       Store Visits       Price Awareness  \n",
       "3       Store Visits       Price Awareness  \n",
       "4       Time Periods         Daily Reports  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Convert the 'event_timestamp' column to datetime format\n",
    "merged_data['event_timestamp'] = pd.to_datetime(merged_data['event_timestamp'])\n",
    "\n",
    "# Extract the month from the date\n",
    "merged_data['month'] = merged_data['event_timestamp'].dt.month\n",
    "\n",
    "# Get the count of entries for each month\n",
    "month_counts = merged_data['month'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "month\n",
       "1       630\n",
       "2       958\n",
       "3     29151\n",
       "4      2487\n",
       "5      1137\n",
       "6      1744\n",
       "7      1850\n",
       "8      1890\n",
       "9      1487\n",
       "10     1059\n",
       "11     1074\n",
       "12     1488\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>event_timestamp</th>\n",
       "      <th>Text_Cleaned</th>\n",
       "      <th>Preprocessed_Text</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Sub-Topic</th>\n",
       "      <th>Topic_</th>\n",
       "      <th>Sub-Topic_</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Today I took advantage of these gas prices and...</td>\n",
       "      <td>2020-07-04</td>\n",
       "      <td>today i took advantage of these gas prices and...</td>\n",
       "      <td>['today', 'took', 'price', 'never', 'given', '...</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>Time Periods</td>\n",
       "      <td>Daily Reports</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Hey Rush Limbaugh why don t you go to your loc...</td>\n",
       "      <td>2020-11-04</td>\n",
       "      <td>hey rush limbaugh why don t you go to your loc...</td>\n",
       "      <td>['go', 'local', 'today', 'senior', 'stage']</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>Store Visits</td>\n",
       "      <td>Price Awareness</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>She said the orders are placed over the phone ...</td>\n",
       "      <td>2020-07-04</td>\n",
       "      <td>she said the orders are placed over the phone ...</td>\n",
       "      <td>['said', 'order', 'place', 'phone', 'via', 'lo...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Online Shopping</td>\n",
       "      <td>Order Pricing</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>COVID-19 has wiped the calendars of experienti...</td>\n",
       "      <td>2020-10-04</td>\n",
       "      <td>covid 19 has wiped the calendars of experienti...</td>\n",
       "      <td>['live', 'event', 'agenc', 'futur', 'forc', 'b...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Consumer Impact</td>\n",
       "      <td>Market Impact</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>The consumer s mindset was already showing sig...</td>\n",
       "      <td>2020-10-04</td>\n",
       "      <td>the consumer s mindset was already showing sig...</td>\n",
       "      <td>['consum', 'alreadi', 'show', 'sign', 'could',...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Consumer Impact</td>\n",
       "      <td>Market Impact</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text event_timestamp  \\\n",
       "4   Today I took advantage of these gas prices and...      2020-07-04   \n",
       "23  Hey Rush Limbaugh why don t you go to your loc...      2020-11-04   \n",
       "25  She said the orders are placed over the phone ...      2020-07-04   \n",
       "30  COVID-19 has wiped the calendars of experienti...      2020-10-04   \n",
       "32  The consumer s mindset was already showing sig...      2020-10-04   \n",
       "\n",
       "                                         Text_Cleaned  \\\n",
       "4   today i took advantage of these gas prices and...   \n",
       "23  hey rush limbaugh why don t you go to your loc...   \n",
       "25  she said the orders are placed over the phone ...   \n",
       "30  covid 19 has wiped the calendars of experienti...   \n",
       "32  the consumer s mindset was already showing sig...   \n",
       "\n",
       "                                    Preprocessed_Text  Topic  Sub-Topic  \\\n",
       "4   ['today', 'took', 'price', 'never', 'given', '...      9          2   \n",
       "23        ['go', 'local', 'today', 'senior', 'stage']      6          2   \n",
       "25  ['said', 'order', 'place', 'phone', 'via', 'lo...      4          1   \n",
       "30  ['live', 'event', 'agenc', 'futur', 'forc', 'b...      5          1   \n",
       "32  ['consum', 'alreadi', 'show', 'sign', 'could',...      5          1   \n",
       "\n",
       "             Topic_       Sub-Topic_  month  \n",
       "4      Time Periods    Daily Reports      7  \n",
       "23     Store Visits  Price Awareness     11  \n",
       "25  Online Shopping    Order Pricing      7  \n",
       "30  Consumer Impact    Market Impact     10  \n",
       "32  Consumer Impact    Market Impact     10  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only take data for month 1 to 6\n",
    "merged_data = merged_data[merged_data['month'] > 6]\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.to_csv('../data/Covid-data-with-topic-names.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the frequency of each topic and store in json file\n",
    "topic_counts = merged_data['Topic_'].value_counts()\n",
    "topic_counts.to_json('../data/topic_counts.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Group by 'Topic_' and 'Sub-Topic_' and calculate the frequency\n",
    "topic_subtopic_counts = merged_data.groupby(['Topic_', 'Sub-Topic_']).size()\n",
    "\n",
    "# Convert the Series to a DataFrame and reset the index\n",
    "topic_subtopic_counts_df = topic_subtopic_counts.reset_index(name='counts')\n",
    "\n",
    "# Create a dictionary to hold the final structure\n",
    "final_dict = {}\n",
    "\n",
    "# Iterate over the DataFrame rows\n",
    "for index, row in topic_subtopic_counts_df.iterrows():\n",
    "    # If the topic is not in the final_dict, add it with an empty list as the value\n",
    "    if row['Topic_'] not in final_dict:\n",
    "        final_dict[row['Topic_']] = []\n",
    "    # Append a dictionary with the sub-topic as the key and the count as the value to the list\n",
    "    final_dict[row['Topic_']].append({row['Sub-Topic_']: row['counts']})\n",
    "\n",
    "# Write the final_dict to a JSON file\n",
    "with open('../data/topic_subtopic_counts.json', 'w') as f:\n",
    "    json.dump(final_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'Topic_' and 'Sub-Topic_' and calculate the frequency\n",
    "topic_subtopic_counts = merged_data.groupby(['Topic_', 'Sub-Topic_']).size()\n",
    "\n",
    "# Convert the Series to a DataFrame and reset the index\n",
    "topic_subtopic_counts_df = topic_subtopic_counts.reset_index(name='counts')\n",
    "\n",
    "# Create a dictionary to hold the final structure\n",
    "final_dict = {}\n",
    "\n",
    "# Iterate over the DataFrame rows\n",
    "for index, row in topic_subtopic_counts_df.iterrows():\n",
    "    # If the topic is not in the final_dict, add it with an empty list as the value\n",
    "    if row['Topic_'] not in final_dict:\n",
    "        final_dict[row['Topic_']] = []\n",
    "    # Append a dictionary with the sub-topic as the key and the count as the value to the list\n",
    "    final_dict[row['Topic_']].append(row['Sub-Topic_'])\n",
    "\n",
    "# Write the final_dict to a JSON file\n",
    "with open('../data/topic_subtopic_data.json', 'w') as f:\n",
    "    json.dump(final_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "merged_data = pd.read_csv('../data/Covid-data-with-topic-names.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Topic_</th>\n",
       "      <th>month</th>\n",
       "      <th>Consumer Impact</th>\n",
       "      <th>Global Economy</th>\n",
       "      <th>Health Measures</th>\n",
       "      <th>Oil Market</th>\n",
       "      <th>Online Shopping</th>\n",
       "      <th>Shopping Behavior</th>\n",
       "      <th>Stay Home</th>\n",
       "      <th>Store</th>\n",
       "      <th>Store Visits</th>\n",
       "      <th>Time Periods</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>240.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>371.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>328.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>257.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>162.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Topic_  month  Consumer Impact  Global Economy  Health Measures  Oil Market  \\\n",
       "0           7            240.0           119.0            184.0       317.0   \n",
       "1           8            371.0            97.0            234.0       174.0   \n",
       "2           9            328.0            77.0            184.0       136.0   \n",
       "3          10            257.0            81.0            132.0        67.0   \n",
       "4          11            162.0            52.0            123.0        64.0   \n",
       "\n",
       "Topic_  Online Shopping  Shopping Behavior  Stay Home  Store  Store Visits  \\\n",
       "0                  92.0              165.0       97.0  256.0         269.0   \n",
       "1                 100.0              171.0       93.0  272.0         288.0   \n",
       "2                  78.0              138.0       60.0  178.0         218.0   \n",
       "3                  70.0              102.0       45.0  105.0         146.0   \n",
       "4                  68.0              159.0       63.0  111.0         198.0   \n",
       "\n",
       "Topic_  Time Periods  \n",
       "0              111.0  \n",
       "1               90.0  \n",
       "2               90.0  \n",
       "3               54.0  \n",
       "4               74.0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by 'month' and 'Topic_' and calculate the frequency\n",
    "month_topic_counts = merged_data.groupby(['month', 'Topic_']).size().reset_index(name='counts')\n",
    "\n",
    "# Pivot the DataFrame for 'Topic_'\n",
    "pivot_topic = month_topic_counts.pivot_table(index='month', columns='Topic_', values='counts', fill_value=0)\n",
    "\n",
    "# Reset the index\n",
    "pivot_topic.reset_index(inplace=True)\n",
    "\n",
    "pivot_topic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Sub-Topic_</th>\n",
       "      <th>month</th>\n",
       "      <th>Business Response</th>\n",
       "      <th>Buying Trends</th>\n",
       "      <th>Consumer Behavior</th>\n",
       "      <th>Customer Waiting</th>\n",
       "      <th>Daily Reports</th>\n",
       "      <th>Demand Changes</th>\n",
       "      <th>Economic Impact</th>\n",
       "      <th>Financial Assistance</th>\n",
       "      <th>Hand Hygiene</th>\n",
       "      <th>...</th>\n",
       "      <th>Paper Purchases</th>\n",
       "      <th>Price Awareness</th>\n",
       "      <th>Price Fluctuations</th>\n",
       "      <th>Price Trends</th>\n",
       "      <th>Price Volatility</th>\n",
       "      <th>Stay-at-home Measures</th>\n",
       "      <th>Stock Market Activity</th>\n",
       "      <th>Store Operations</th>\n",
       "      <th>Weekly Trends</th>\n",
       "      <th>Worker Safety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>48.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>84.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>57.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>...</td>\n",
       "      <td>58.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>41.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>34.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Sub-Topic_  month  Business Response  Buying Trends  Consumer Behavior  \\\n",
       "0               7               48.0           50.0               49.0   \n",
       "1               8               84.0           53.0               36.0   \n",
       "2               9               57.0           59.0               23.0   \n",
       "3              10               41.0           37.0               34.0   \n",
       "4              11               34.0           67.0               15.0   \n",
       "\n",
       "Sub-Topic_  Customer Waiting  Daily Reports  Demand Changes  Economic Impact  \\\n",
       "0                       79.0           23.0            87.0             29.0   \n",
       "1                       69.0           27.0            80.0             36.0   \n",
       "2                       41.0           28.0            70.0             34.0   \n",
       "3                       30.0           18.0            61.0             31.0   \n",
       "4                       48.0           25.0            46.0             23.0   \n",
       "\n",
       "Sub-Topic_  Financial Assistance  Hand Hygiene  ...  Paper Purchases  \\\n",
       "0                           77.0          58.0  ...             42.0   \n",
       "1                           66.0          66.0  ...             66.0   \n",
       "2                           48.0          57.0  ...             58.0   \n",
       "3                           39.0          42.0  ...             40.0   \n",
       "4                           58.0          50.0  ...             61.0   \n",
       "\n",
       "Sub-Topic_  Price Awareness  Price Fluctuations  Price Trends  \\\n",
       "0                      92.0                38.0         112.0   \n",
       "1                     111.0                52.0          57.0   \n",
       "2                      72.0                31.0          44.0   \n",
       "3                      57.0                26.0          21.0   \n",
       "4                      60.0                34.0          30.0   \n",
       "\n",
       "Sub-Topic_  Price Volatility  Stay-at-home Measures  Stock Market Activity  \\\n",
       "0                      102.0                   48.0                   42.0   \n",
       "1                       56.0                   36.0                   30.0   \n",
       "2                       36.0                   30.0                   26.0   \n",
       "3                       14.0                   22.0                   14.0   \n",
       "4                       15.0                   33.0                   26.0   \n",
       "\n",
       "Sub-Topic_  Store Operations  Weekly Trends  Worker Safety  \n",
       "0                       47.0           46.0          130.0  \n",
       "1                       50.0           33.0          153.0  \n",
       "2                       44.0           36.0           93.0  \n",
       "3                       28.0           22.0           47.0  \n",
       "4                       32.0           23.0           31.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by 'month' and 'Sub-Topic_' and calculate the frequency\n",
    "month_subtopic_counts = merged_data.groupby(['month', 'Sub-Topic_']).size().reset_index(name='counts')\n",
    "\n",
    "# Pivot the DataFrame for 'Sub-Topic_'\n",
    "pivot_subtopic = month_subtopic_counts.pivot_table(index='month', columns='Sub-Topic_', values='counts', fill_value=0)\n",
    "\n",
    "# Reset the index\n",
    "pivot_subtopic.reset_index(inplace=True)\n",
    "\n",
    "pivot_subtopic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>Consumer Impact</th>\n",
       "      <th>Global Economy</th>\n",
       "      <th>Health Measures</th>\n",
       "      <th>Oil Market</th>\n",
       "      <th>Online Shopping</th>\n",
       "      <th>Shopping Behavior</th>\n",
       "      <th>Stay Home</th>\n",
       "      <th>Store</th>\n",
       "      <th>Store Visits</th>\n",
       "      <th>...</th>\n",
       "      <th>Paper Purchases</th>\n",
       "      <th>Price Awareness</th>\n",
       "      <th>Price Fluctuations</th>\n",
       "      <th>Price Trends</th>\n",
       "      <th>Price Volatility</th>\n",
       "      <th>Stay-at-home Measures</th>\n",
       "      <th>Stock Market Activity</th>\n",
       "      <th>Store Operations</th>\n",
       "      <th>Weekly Trends</th>\n",
       "      <th>Worker Safety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>240.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>371.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>328.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>...</td>\n",
       "      <td>58.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>257.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>162.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   month  Consumer Impact  Global Economy  Health Measures  Oil Market  \\\n",
       "0      7            240.0           119.0            184.0       317.0   \n",
       "1      8            371.0            97.0            234.0       174.0   \n",
       "2      9            328.0            77.0            184.0       136.0   \n",
       "3     10            257.0            81.0            132.0        67.0   \n",
       "4     11            162.0            52.0            123.0        64.0   \n",
       "\n",
       "   Online Shopping  Shopping Behavior  Stay Home  Store  Store Visits  ...  \\\n",
       "0             92.0              165.0       97.0  256.0         269.0  ...   \n",
       "1            100.0              171.0       93.0  272.0         288.0  ...   \n",
       "2             78.0              138.0       60.0  178.0         218.0  ...   \n",
       "3             70.0              102.0       45.0  105.0         146.0  ...   \n",
       "4             68.0              159.0       63.0  111.0         198.0  ...   \n",
       "\n",
       "   Paper Purchases  Price Awareness  Price Fluctuations  Price Trends  \\\n",
       "0             42.0             92.0                38.0         112.0   \n",
       "1             66.0            111.0                52.0          57.0   \n",
       "2             58.0             72.0                31.0          44.0   \n",
       "3             40.0             57.0                26.0          21.0   \n",
       "4             61.0             60.0                34.0          30.0   \n",
       "\n",
       "   Price Volatility  Stay-at-home Measures  Stock Market Activity  \\\n",
       "0             102.0                   48.0                   42.0   \n",
       "1              56.0                   36.0                   30.0   \n",
       "2              36.0                   30.0                   26.0   \n",
       "3              14.0                   22.0                   14.0   \n",
       "4              15.0                   33.0                   26.0   \n",
       "\n",
       "   Store Operations  Weekly Trends  Worker Safety  \n",
       "0              47.0           46.0          130.0  \n",
       "1              50.0           33.0          153.0  \n",
       "2              44.0           36.0           93.0  \n",
       "3              28.0           22.0           47.0  \n",
       "4              32.0           23.0           31.0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the two DataFrames on 'month'\n",
    "merged_df = pd.merge(pivot_topic, pivot_subtopic, on='month')\n",
    "\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('../data/month_topic_subtopic_counts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ['today', 'took', 'price', 'never', 'given', '...\n",
       "1          ['go', 'local', 'today', 'senior', 'stage']\n",
       "2    ['said', 'order', 'place', 'phone', 'via', 'lo...\n",
       "3    ['live', 'event', 'agenc', 'futur', 'forc', 'b...\n",
       "4    ['consum', 'alreadi', 'show', 'sign', 'could',...\n",
       "Name: Preprocessed_Text, dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data['Preprocessed_Text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "from math import log\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_correlation_matrix(df):\n",
    "    # Initialize a Counter object to count word occurrences and co-occurrences\n",
    "    word_counts = Counter()\n",
    "    co_occurrence_counts = Counter()\n",
    "\n",
    "    # Initialize the total number of words\n",
    "    total_words = 0\n",
    "\n",
    "    # Iterate over the rows of the DataFrame\n",
    "    for _, row in df.iterrows():\n",
    "        # Get the list of words in the \"Preprocessed_Text\" column\n",
    "        words = ast.literal_eval(row['Preprocessed_Text'])\n",
    "\n",
    "        # Increment the count for each word\n",
    "        for word in words:\n",
    "            word_counts[word] += 1\n",
    "            total_words += 1\n",
    "\n",
    "        # For each pair of words, increment the count\n",
    "        for word1, word2 in combinations(words, 2):\n",
    "            if word1 != word2:\n",
    "                co_occurrence_counts[(word1, word2)] += 1\n",
    "\n",
    "    # Initialize a DataFrame with zeros\n",
    "    correlation_matrix = pd.DataFrame(0.0, index=word_counts.keys(), columns=word_counts.keys())\n",
    "\n",
    "    # Calculate the correlation scores\n",
    "    for word1 in word_counts.keys():\n",
    "        for word2 in word_counts.keys():\n",
    "            if word1 != word2:\n",
    "                # Calculate the joint probability of the words\n",
    "                p_word1_word2 = co_occurrence_counts[(word1, word2)] / total_words\n",
    "\n",
    "                # Calculate the marginal probabilities of the words\n",
    "                p_word1 = word_counts[word1] / total_words\n",
    "                p_word2 = word_counts[word2] / total_words\n",
    "\n",
    "                # Add a small constant for smoothing\n",
    "                epsilon = 1e-10\n",
    "\n",
    "                # Calculate the NPMI score\n",
    "                npmi_score = log((p_word1_word2 + epsilon) / (p_word1 * p_word2 + epsilon)) / -log(p_word1_word2 + epsilon)\n",
    "\n",
    "                correlation_matrix.loc[word1, word2] = npmi_score\n",
    "\n",
    "    return correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/Covid-data-with-topic-names.csv')\n",
    "    \n",
    "# Group the data by month and topic\n",
    "grouped_data = df.groupby(['month', 'Topic_'])\n",
    "\n",
    "# Initialize a dictionary to store the top 5 frequent words for each topic and each month\n",
    "top_words = {\"Topics\": list(df['Topic_'].unique()), \"Data\": []}\n",
    "\n",
    "\n",
    "# Calculate the correlation matrix for all words\n",
    "correlation_matrix = calculate_correlation_matrix(df)\n",
    "\n",
    "# save the correlation matrix to a csv file\n",
    "correlation_matrix.to_csv('../data/correlation_matrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['Topic_'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>event_timestamp</th>\n",
       "      <th>Text_Cleaned</th>\n",
       "      <th>Preprocessed_Text</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Sub-Topic</th>\n",
       "      <th>Topic_</th>\n",
       "      <th>Sub-Topic_</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COVID-19 has wiped the calendars of experienti...</td>\n",
       "      <td>2020-10-04</td>\n",
       "      <td>covid 19 has wiped the calendars of experienti...</td>\n",
       "      <td>['live', 'event', 'agenc', 'futur', 'forc', 'b...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Consumer Impact</td>\n",
       "      <td>Market Impact</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The consumer s mindset was already showing sig...</td>\n",
       "      <td>2020-10-04</td>\n",
       "      <td>the consumer s mindset was already showing sig...</td>\n",
       "      <td>['consum', 'alreadi', 'show', 'sign', 'could',...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Consumer Impact</td>\n",
       "      <td>Market Impact</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Covid 19 will accelerate this trend towards E...</td>\n",
       "      <td>2020-08-04</td>\n",
       "      <td>covid 19 will accelerate this trend towards es...</td>\n",
       "      <td>['even', 'creat', 'respons', 'everyth', 'consu...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Consumer Impact</td>\n",
       "      <td>Market Impact</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Department stores lead a group of consumer com...</td>\n",
       "      <td>2020-08-04</td>\n",
       "      <td>department stores lead a group of consumer com...</td>\n",
       "      <td>['depart', 'store', 'lead', 'group', 'consum',...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Consumer Impact</td>\n",
       "      <td>Demand Changes</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Brands dont need to change campaigns - succe...</td>\n",
       "      <td>2020-10-04</td>\n",
       "      <td>brands dont need to change campaigns to succe...</td>\n",
       "      <td>['brand', 'need', 'chang', 'campaign', 'succes...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Consumer Impact</td>\n",
       "      <td>Market Impact</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>The world has shifted left, right and centre a...</td>\n",
       "      <td>2020-12-03</td>\n",
       "      <td>the world has shifted left right and centre an...</td>\n",
       "      <td>['world', 'left', 'right', 'centr', 'yet', 'br...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Consumer Impact</td>\n",
       "      <td>Business Response</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>Completely changed my outlook on Covid-19.. Ti...</td>\n",
       "      <td>2020-11-03</td>\n",
       "      <td>completely changed my outlook on covid 19. tim...</td>\n",
       "      <td>['complet', 'chang', 'time', 'stock']</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Consumer Impact</td>\n",
       "      <td>Business Response</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>New Revelations - Keep a mint handy, apart fro...</td>\n",
       "      <td>2020-11-04</td>\n",
       "      <td>new revelations to keep a mint handy apart fro...</td>\n",
       "      <td>['new', 'keep']</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Consumer Impact</td>\n",
       "      <td>Business Response</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>https://t.co/Yu5L6PzGkk How To Pay Off Your Ho...</td>\n",
       "      <td>2020-11-04</td>\n",
       "      <td>6556\\r\\r brandimage capital amounts to eur 453...</td>\n",
       "      <td>['amount', 'share', 'common', 'stock', 'valu',...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Consumer Impact</td>\n",
       "      <td>Business Response</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>The clowns are playing games with #COVID2019 a...</td>\n",
       "      <td>2020-11-03</td>\n",
       "      <td>the clowns are playing games with and peoples ...</td>\n",
       "      <td>['play', 'game', 'peopl', 'live', 'larg', 'par...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Consumer Impact</td>\n",
       "      <td>Business Response</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text event_timestamp  \\\n",
       "3     COVID-19 has wiped the calendars of experienti...      2020-10-04   \n",
       "4     The consumer s mindset was already showing sig...      2020-10-04   \n",
       "6      Covid 19 will accelerate this trend towards E...      2020-08-04   \n",
       "11    Department stores lead a group of consumer com...      2020-08-04   \n",
       "14    Brands dont need to change campaigns - succe...      2020-10-04   \n",
       "...                                                 ...             ...   \n",
       "1315  The world has shifted left, right and centre a...      2020-12-03   \n",
       "1623  Completely changed my outlook on Covid-19.. Ti...      2020-11-03   \n",
       "1635  New Revelations - Keep a mint handy, apart fro...      2020-11-04   \n",
       "1698  https://t.co/Yu5L6PzGkk How To Pay Off Your Ho...      2020-11-04   \n",
       "1703  The clowns are playing games with #COVID2019 a...      2020-11-03   \n",
       "\n",
       "                                           Text_Cleaned  \\\n",
       "3     covid 19 has wiped the calendars of experienti...   \n",
       "4     the consumer s mindset was already showing sig...   \n",
       "6     covid 19 will accelerate this trend towards es...   \n",
       "11    department stores lead a group of consumer com...   \n",
       "14    brands dont need to change campaigns to succe...   \n",
       "...                                                 ...   \n",
       "1315  the world has shifted left right and centre an...   \n",
       "1623  completely changed my outlook on covid 19. tim...   \n",
       "1635  new revelations to keep a mint handy apart fro...   \n",
       "1698  6556\\r\\r brandimage capital amounts to eur 453...   \n",
       "1703  the clowns are playing games with and peoples ...   \n",
       "\n",
       "                                      Preprocessed_Text  Topic  Sub-Topic  \\\n",
       "3     ['live', 'event', 'agenc', 'futur', 'forc', 'b...      5          1   \n",
       "4     ['consum', 'alreadi', 'show', 'sign', 'could',...      5          1   \n",
       "6     ['even', 'creat', 'respons', 'everyth', 'consu...      5          1   \n",
       "11    ['depart', 'store', 'lead', 'group', 'consum',...      5          0   \n",
       "14    ['brand', 'need', 'chang', 'campaign', 'succes...      5          1   \n",
       "...                                                 ...    ...        ...   \n",
       "1315  ['world', 'left', 'right', 'centr', 'yet', 'br...      5          2   \n",
       "1623              ['complet', 'chang', 'time', 'stock']      5          2   \n",
       "1635                                    ['new', 'keep']      5          2   \n",
       "1698  ['amount', 'share', 'common', 'stock', 'valu',...      5          2   \n",
       "1703  ['play', 'game', 'peopl', 'live', 'larg', 'par...      5          2   \n",
       "\n",
       "               Topic_         Sub-Topic_  month  \n",
       "3     Consumer Impact      Market Impact     10  \n",
       "4     Consumer Impact      Market Impact     10  \n",
       "6     Consumer Impact      Market Impact      8  \n",
       "11    Consumer Impact     Demand Changes      8  \n",
       "14    Consumer Impact      Market Impact     10  \n",
       "...               ...                ...    ...  \n",
       "1315  Consumer Impact  Business Response     12  \n",
       "1623  Consumer Impact  Business Response     11  \n",
       "1635  Consumer Impact  Business Response     11  \n",
       "1698  Consumer Impact  Business Response     11  \n",
       "1703  Consumer Impact  Business Response     11  \n",
       "\n",
       "[90 rows x 9 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/Covid-data-with-topic-names.csv')\n",
    "    \n",
    "topic_name = 'Consumer Impact'\n",
    "# Group the data by month and topic\n",
    "grouped_data = df[df[\"Topic_\"] == topic_name].groupby(['month', 'Sub-Topic_'])\n",
    "grouped_data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
